[{"authors":null,"categories":null,"content":"I am a passionate computer science student moving his first steps as a researcher.\nMy interests span across various topics of the field, with a focus on artificial intelligence; I am particularly excited by causality, meta-learning and geometric deep learning, especially when graphs are involved.\n Download my resumé. -- ","date":1461110400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1607817600,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"I am a passionate computer science student moving his first steps as a researcher.\nMy interests span across various topics of the field, with a focus on artificial intelligence; I am particularly excited by causality, meta-learning and geometric deep learning, especially when graphs are involved.","tags":null,"title":"Donato Crisostomi","type":"authors"},{"authors":null,"categories":null,"content":" Coming soon!  ","date":1603152000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1603152000,"objectID":"3196788ab4862f540a103157bbd1a541","permalink":"//localhost:1313/project/tsp-sc/","publishdate":"2020-10-20T00:00:00Z","relpermalink":"/project/tsp-sc/","section":"project","summary":"Extension of the graph signal processing framework to simplicial complexes, with applications on real world scenarios.","tags":["Geometric Deep Learning","Social Networks","Graph Machine Learning","Deep Learning","Signal Processing"],"title":"Topological Signal Processing over Simplicial Complexes (WIP)","type":"project"},{"authors":null,"categories":null,"content":"Introduction Richard Feynman once said that\n  What I cannot create, I do not understand.\n  and, in the context of machine learning, this means that for machines to understand their input data, they should learn to create it. Moreover, being able to generate unseen images opens the door to some groundshaking applications, from super-resolution, to text-to-image translation (Ledig et al. 2016; Gorti and Ma 2018).\nImage synthesis nevertheless has been one of the most challenging tasks for machine learning to tackle. In fact, generative models are needed to generate new unseen images; but while we witnessed a huge leap forward in discriminative models during the first years of the last decade thanks to neural architectures, generative models initially failed to keep up. It was in \\(2014\\) that Goodfellow et al. came up with Generative Adversarial Networks (Goodfellow et al. 2014). GANs and their evolutions have been the state-of-the-art since then, but a very recent paper shows that similar performance can be obtained with a different model that leverages probabilistic diffusion in order to generate images (Ho, Jain, and Abbeel 2020).\nGenerative models have also been particularly useful to create artificial examples in order to augment datasets (Santos Tanaka and Aranha 2019), but in order to generate new images belonging to a certain class, one would need to have a conditional model. Goal of this research is therefore to integrate class-conditionality in probabilistic diffusion models.\nRelated work As anticipated, the most used generative architecture is Generative Adversarial Networks (Goodfellow et al. 2014), which is composed of two networks that are trained adversarily: a generator is trained in such a way that a discriminator cannot distinguish between its generated samples and the real ones, while simultaneously training the discriminator to be able to distinguish between fake samples and real ones. To integrate class-conditionality in GANs, various approaches have been tried: Brock et al. provide class information to the generator with conditional batch norm (Brock, Donahue, and Simonyan 2018), while Odena et al. leverage an auxiliary classifier (Odena, Olah, and Shlens 2017).\nProposed method A diffusion probabilistic model is a parameterized Markov chain: A Markov chain models the state of a system with a random variable that changes through time. For the Markov property to hold, the distribution of a state must depend only on the distribution of the previous state.\n The directed graphical model used in the project.  The training phase consists of two phases: a forward pass and a reverse pass, as can be seen in 1. In the former, also called the diffusion process, Gaussian noise is added to the image according to a fixed schedule so each transition in the Markov chain \\(q(\\mathbf{x}_{t}| \\mathbf{x}_{t-1})\\) represents the addition of Gaussian noise. In the latter, the transitions of a reverse Markov chain are learned in order to reconstruct the destroyed signal; the parameters are learned by optimizing the variational bound on negative loglikelihood:\n\\[\\begin{align} \\mathbb{E}\\left[ - \\log p_{\\theta}(\\mathbf{x}_0) \\right] \u0026amp;\\leq \\mathbb{E}_q \\left[ - \\log \\frac{p_\\theta (\\mathbf{x}_0, \\dots, \\mathbf{x}_T)}{q(\\mathbf{x}_1, \\dots, \\mathbf{x}_T|\\mathbf{x}_0)}\\right] \\\\ \u0026amp;= \\mathbb{E}_q\\left[ - \\log \\ p(\\mathbf{x}_T) - \\sum_{t \\geq 1} \\log \\frac{p_\\theta (\\mathbf{x}_{t-1}|\\mathbf{x}_t)}{q(\\mathbf{x}_t | \\mathbf{x}_{t-1})} \\right] \\end{align}\\]\n We employ the architecture suggested by the original paper, in which the denoiser is a U-Net (Ronneberger, Fischer, and Brox 2015), shown in 2.\n The popular U-Net architecture used for the denoiser.  Conditional Batch Norm Conditional Batch Normalization was first applied to language-vision tasks to implement the intuition that the linguistic input should modulate the entire visual processing, instead of being fused only in the last part of the process. CBN builds upon Batch Normalization, in which each batch is normalized as follows to reduce the internal co-variate shift \\[\\text{BN}_{\\gamma, \\beta}(x_i) = \\gamma_i \\frac{x_i - \\mathbb{E}(x_i)}{\\sqrt{var(x_i)}} + \\beta_i\\] In CBN we want to predict \\(\\gamma\\) and \\(\\beta\\) from an embedding of the class, so that the class may manipulate entire feature maps by scaling them up or down, negating them, or shutting them off completely (Odena, Olah, and Shlens 2017).\nThe integration of CBN in the architecture is done by replacing the Batch Norm layers inside the denoiser architecture with conditional ones. We are going to refer to the model obtained by adding CBN to the original model as \\(M_{CBN}\\).\nAuxiliary Classifier Analogously to what has been done in (Odena, Olah, and Shlens 2017) for GANs, we have added an auxiliary classifier to the original architecture of the denoiser.\nTo provide the class information to the denoiser, the label is embedded and reshaped to be the same dimension as one of the channels of the image, i.e. \\(w \\times h\\), and then concatenated to the input image in the channel dimension. Images are thus tensors of shape \\((b, c+1, w, h)\\), where \\(b\\) is the batch size, \\(c\\) is the number of channels (RGB), \\(w\\) is the width and \\(h\\) is the height.\nThe overall loss is then obtained as a weighted sum of the variational loss to account for the reconstruction error, and the classifier loss, which is a categorical cross entropy, where the weight is a hyper-parameter. The loss should this way be enriched with class information that should backpropagate to the parameters that are involved in the generation.\nWe are going to refer to the model obtained by adding the auxiliary classifier to the original model as \\(M_{AC}\\).\nDataset We based our implementation on the following repository denoising-diffusion-pytorch, which provides a working PyTorch baseline.\nOur original goal was to apply the model to the insect-pest dataset to create new artificial samples for dataset augmentation. The original dataset consisted of over \\(75k\\) images, but most of the classes had few samples and low variance between them, we therefore used a subsample of \\(5\\) classes, ammounting to \\(\\approx 25\\)k samples. The dataset is not really what a data scientist would dream of, as no bounding boxes were provided, and it is often hard even for humans to understand what’s in the image. To attribute the right degree of responsibility to the model and to the dataset, we also tested the model on a different dataset from Stanford, containing \\(\\approx 20k\\) images of cars.\nTo test our proposed conditional methods, to simplify the visual inspection of the results, we instead created an ad-hoc dataset of only two classes with the aim of maximizing the difference between them. To this end, we took a subset of \\(\\approx 10k\\) images from the Stanford dogs (Khosla et al. 2011) and the Stanford cars (Krause et al. 2013) datasets.\nResults All the unconditional and conditional versions of the model that follow have been trained for \\(\\approx 100\\) epochs. The unconditional model was tested both on low resolution sample and higher resolution ones, yielding the results that follow.\n    64 128         As it is evident from the samples, the resolution plays a strong role in generating realistic images, providing the model more information to leverage for the generation. The Inception Scores are as follow\n    64 128    insects 4.2 4.08  cars 3.32      Regarding the conditional model, the two proposed methods yielded totally different results. \\(M_{CBN}\\) converges to a small reconstruction error, and the class of the generated images can often be inferred visually; see for example 6 which is a batch of generated images for the ‘dog’ class and 7 which is a batch of generated images for the ‘car’ class.\n    class ‘dog’ class ‘car’         Nevertheless, the results appear as messy color spots which do not resemble any realistic image. As the reconstruction error is small, the problem seems to be related to the sampling procedure, and indeed it might be the case that the class information is not accounted for correctly during sampling, as the CBN is only part of the denoiser and class information does not influence the rest of the sampling process.\n t-sne plot of the images generated by \\(M_{CBN}\\).  To check whether there is a class-related distinction between the generated images, we plotted the images with t-SNE, yielding the results that can be seen in 11 and 12. The points seem to be fairly separable, indicating that the class is indeed infused in the generated images.\n t-sne plot of the images generated by \\(M_{CBN}\\) with each point visualized as the image that it embeds.  \\(M_{AC}\\) instead results in the converse, yielding almost realistic images that do not seem to be much influenced by the class. As a first attempt, we tried training the random-initialized classifier with the rest of the architecture; this resulted in a rapidly decreasing classifier loss that did not help the generation at all, but instead seemed to only worsen the results. To our advise, this was due to a process of co-adaption in which the parameters of one computational block were set to satisfy the other, and viceversa. To address this issue, we pretrained the classifier until convergence on the dataset of real images and then kept its parameters fixed during the training of the rest of the model. This yielded the results in 8 and 9;\n    class ‘dog’ class ‘car’         The images resemble cars, mostly ignoring the input label. We eventually tried feeding higher-resolution images to the model, but with no significant improvement. The generated images in fact do not resemble their class, but the classification loss still goes rapidly down; to provide an explanation, we visually inspected the images and found out that artifacts were present in every image (10), probably resulting from the generator ‘tricking’ the classifier, emphasizing features that resulted in high confidence guesses in the latter.\n Images generated by \\(M_{AC}\\) when supplied class ‘car’ at resolution \\(128\\); artifacts are circled.  We concluded that the model was not robust enough, and therefore tried to employ a finetuned ResNet18 classifier, but this did not solve the issue.\n t-sne plot of the images generated by \\(M_{AC}\\).  As before, we plotted the images with t-SNE to check whether there is a class-related distinction between the images; as can be seen in 13 and 14, this time the points are all mixed up, indicating that the model fails to conditionate the generation on the class.\n t-sne plot of the images generated by \\(M_{AC}\\) with each point visualized as the image that it embeds.  Conclusions The proposed methods do not yield acceptable results, indicating that it is not enough to adapt GANs techniques for class-conditionality to probabilistic diffusion models, while this is also not straightforward to do. This also emphasizes that, while seemingly close to GANs, this family of models requires ad-hoc research, as they are based on different theorical aspects.\nReferences Brock, Andrew, Jeff Donahue, and Karen Simonyan. 2018. “Large Scale GAN Training for High Fidelity Natural Image Synthesis.” CoRR abs/1809.11096. http://arxiv.org/abs/1809.11096.  Goodfellow, Ian J., Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. 2014. “Generative Adversarial Networks.” http://arxiv.org/abs/1406.2661.  Gorti, Satya Krishna, and Jeremy Ma. 2018. “Text-to-Image-to-Text Translation Using Cycle Consistent Adversarial Networks.” CoRR abs/1808.04538. http://arxiv.org/abs/1808.04538.  Ho, Jonathan, Ajay Jain, and Pieter Abbeel. 2020. “Denoising Diffusion Probabilistic Models.” http://arxiv.org/abs/2006.11239.  Khosla, Aditya, Nityananda Jayadevaprakash, Bangpeng Yao, and Li Fei-Fei. 2011. “Novel Dataset for Fine-Grained Image Categorization.” In First Workshop on Fine-Grained Visual Categorization, IEEE Conference on Computer Vision and Pattern Recognition. Colorado Springs, CO.  Krause, Jonathan, Michael Stark, Jia Deng, and Li Fei-Fei. 2013. “3d Object Representations for Fine-Grained Categorization.” In 4th International IEEE Workshop on 3d Representation and Recognition (3dRR-13). Sydney, Australia.  Ledig, Christian, Lucas Theis, Ferenc Huszar, Jose Caballero, Andrew P. Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, and Wenzhe Shi. 2016. “Photo-Realistic Single Image Super-Resolution Using a Generative Adversarial Network.” CoRR abs/1609.04802. http://arxiv.org/abs/1609.04802.  Odena, Augustus, Christopher Olah, and Jonathon Shlens. 2017. “Conditional Image Synthesis with Auxiliary Classifier GANs.” http://arxiv.org/abs/1610.09585.  Ronneberger, Olaf, Philipp Fischer, and Thomas Brox. 2015. “U-Net: Convolutional Networks for Biomedical Image Segmentation.” CoRR abs/1505.04597. http://arxiv.org/abs/1505.04597.  Santos Tanaka, Fabio Henrique Kiyoiti dos, and Claus Aranha. 2019. “Data Augmentation Using GANs.” CoRR abs/1904.09135. http://arxiv.org/abs/1904.09135.   ","date":1607990400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607990400,"objectID":"10c09e4cd827964b91d1b50cc9475bb6","permalink":"//localhost:1313/project/is/","publishdate":"2020-12-15T00:00:00Z","relpermalink":"/project/is/","section":"project","summary":"Testing of various approaches for the integration of conditionality into probabilistic diffusion models for image synthesis.","tags":["Generative","Deep Learning","Computer Vision"],"title":"Towards Conditionality for Probabilistic Diffusion Models","type":"project"},{"authors":null,"categories":null,"content":"Introduction Motivation What is virality? Virality, in its original meaning, refers to viruses that can only survive by continously spreading from one host to another in a parasitic manner; Actually, many real life phenomena exhibit a spreading behaviour to which we can extend the notion of virality.\nThe ability to predict the spreading potential of a certain signal has evident benefits, for example providing a mean to prevent the spread of undesired phenomena such as diseases or fake news, but also allowing companies to exploit this information to improve their advertising campaigns.\nGraphs serve as an useful abstraction to model real world situations, and are well suited to represent spreading patterns:\n nodes represent components of interest (e.g. users in a social network);\n edges define existing relations among these components;\n node signal represents the information, which is generated from some source node, and is propagated to its neighboring nodes through its edges, possibly iterating the process until all the nodes have been reached.\n  Task formalization A spreading piece of information \\(m\\) originates a cascade in the network, to formalize the problem as a learning task we distinguish two sets, namely\n early adopters, and\n final adopters.\n  The former are the ones producing the information as they don’t receive it from other nodes, while the latter are those who adopt the information at the end of the propagation process, or, if you think about it as a disease, those who get infected.\n Spreading process.  In the example, the information is originally produced by nodes \\(a\\) and \\(e\\) independently, and is then spread in subsequent moments until it stops. The final adopters will be all the nodes who have been reached by the information, including the early adopters.\nSo, after a preprocessing step, each node will be characterized by the following two features\n whether it is an early adopter: \\[s_{v}^{(0)} = \\text{initial activation state of node } v\\]\n and whether it is a final adopter, which is the label we want to predict: \\[s_{v}^{(T)} = \\text{final activation state of node } v\\]\n  The final virality coefficient for the piece of information \\(m\\) is eventually obtained by counting the final adopters. \\[\\mathcal{P}_{m} = \\sum_{v \\in \\mathcal{V}} s_{v}^{(T)} = n_{\\infty}^m\\]\nApproaches As a node prediction task, both feature-based methods and representation learning methods can be exploited. The former approach heavily depends on the quality of the hand-crafted features, which are generally extracted heuristically, while the latter allows to automatically learn representations of node statuses which are suited for the task at hand. A possible way to do this is by embedding the graphs into a vector space, and then using conventional representation learning techniques; nevertheless, a more natural approach would be to instead generalize the machine learning models to non-euclidean domains: in the case of deep learning models, this is usually called geometric deep learning.\nData For our task, both synthetic data and real world data have been used.\nSynthetic data The synthetic data generation involves two steps:\ngenerating the social structure of interest;\n generating a certain number of information cascades;\n  Social structure To artificially generate a social network structure which resembles a real one, random graph models are usually used. A good model should allow creating graphs for which the degree distribution follows a power-law, as happens in real social networks.\nA power law is a functional relationship \\(y = ax^{-c}\\) between two quantities, where one quantity varies as a power of the other.\nBy applying the logarithm to both parts we have that \\[\\begin{aligned} y \u0026amp;= ax^{-c} \\\\ log(y) \u0026amp;= log(ax^{-c}) \\\\ log(y) \u0026amp;= log(a) -c \\cdot log(x)\\end{aligned}\\] As a consequence, we get that a power law appears as a line in a log log scale plot, as can be seen in the Twitter degree distribution in figure.\n Twitter degree distribution.  In the social network context it means that it is exponentially more likely to pick “normal people” with few friends or followers rather than popular profiles, called “celebrities” or “authorities”.\nFor this reason we opted for a preferential attachment model, which works in the following way: you begin with a single node with a self loop, when you have built a graph with \\(N-1\\) nodes, you add the \\(N\\)-th node with an edge that goes from \\(N\\) to a node \\(i\\) chosen accordingly with a probability proportional to the degree of \\(i\\).\nInductive definition of the model:\n Base step: \\(G_1\\) is a single node with a self loop;\n Inductive step (for \\(i = 2, 3, \\ldots\\)):\nadd node \\(i\\) to \\(G_i\\);\n add a “half edge” coming out from node \\(i\\);\n choose a node \\(j\\) randomly with probability proportional to its degree, i.e., \\(P\\left\\{\\text{neighbor of $N$ is $i$}\\right\\} = \\frac{deg(i)}{\\sum_{k=1}^{N} deg(k)}\\), where the denominator is a normalization factor;\n close the half edge from \\(i\\), by connecting it to \\(j\\).\n   Information cascades The cascades are generated with the Independent Cascades model, which works in the following way: Let’s assume we have \\(k\\) nodes holding some piece of information (the seed set), the time is discrete and this information spreads over time.\n at time \\(t_0\\) the only persons having the information will be the ones in the seed seet;\n at time \\(t_i\\) for each of the edges incident on the nodes having the information we will be flipping a coin:\n with prob \\(p\\) the information will spread on that edge;\n else the edge is lost forever.\n   Real data Similarly to the synthetic data generation, the process to obtain real data from Twitter involved two steps:\n retrieving the social network relative to a subgraph of Twitter;\n obtaining the cascades from the tweets of the users in the subgraph.\n  Social structure To obtain a subgraph of Twitter we scraped the social network in a Breadth First-fashion\n start with a queue containing a random english speaking user;\n collect all his followers and followees and add them to the queue;\n pop the next user from the queue and repeat step 2 until the desired number of users is reached;\n  Cascades Given the set of users \\(U\\) collected in the previous step, we obtained all the tweets published by users in \\(U\\) that fell in a certain time-window.\nSo, obtained the hashtags from the set of tweets, we recreate for each distinct hashtag a propagation cascade in the following way:\norder the tweets containing the hashtags by timestamp;\n create the first cascade with the first tweet author as root node;\n for each remaining tweet \\(t\\):\nlet \\(u\\) be the node relative to the author of \\(t\\);\n if \\(u\\) has an incoming edge from an existing cascade tree \\(c\\), then add it to \\(c\\);\n else create a new cascade tree with \\(u\\) as root;\n   The roots of the cascade trees were used as early adopters, the remaining nodes as final.\nThe scraping process resulted in a dataset containing \\(~30k\\) users connected by \\(~400k\\) edges, which published a total of \\(12912921\\) tweets. Among these, [..] contained hashtags, if an hashtag was posted more than once from the same user in the given time window it was considered only once.\nSparsity The collected dataset, as you can see in the first plot, suffers from severe sparsity; Most of the hashtags appear in tweets of just one or two distinct authors.\n image  Even worse, also ignoring hashtags which have been tweeted only by one author, most of the cascades are shallow.\nIn the piechart, we see that among all the cascades the great majority of them is just made of a single node, meaning that in most cases there is no spreading tree structure at all, but rather a set of indipendent nodes who hold the same information.\n image  This is due to two reasons:\n first, virality is intrinsecally rare: this may result surprising to us because we can come up with many viral examples, but this is a biased sampling because all the contents which are not viral don’t come up to our minds because we never see them at all; If we take the ratio of viral contents over all the contents we would in fact see that they are a great minority;\n second, we are observing a small subnetwork of the real social network; this way, cascades that would be deep in the real network may instead appear to us a set of independent shallow cascades, as the subgraph is by construction incomplete and may therefore miss the nodes which keep the subcascades connected in the real network;\n  Node features The representation learning techniques may fail to capture some local node properties, for this reason these can be preprocessed and used to enrich the nodes before passing them as input to the model;\nFor each node, we computed the following features:\n local clustering coefficient, which quantifies how close its neighbours are to being a clique; \\[\\begin{aligned} C_{i} \u0026amp;= \\frac{\\text{# of existing edges in $N(v_i)$} }{\\text{# of all possible edges in $N(v_i)$}} \\end{aligned}\\] where \\(N(v_i)\\) is the neighborhood of \\(v_i\\) and \\(n_i\\) is the number of neighbors \\(|N(v_i)|\\).\n eigenvector centrality, which measures the node influence in the network based on the concept that connections to high-scoring nodes contribute more to the score of the node in question than equal connections to low-scoring nodes;\n PageRank coefficient, which is a kind of eigenvector centrality which was originally used by Google to represent the likelihood that a person randomly clicking on links will arrive at any particular webpage;\n Authority and Hubs coefficients, the intuition here is that a good hub represents a node that points to many other node, while a good authority represents a node that is linked by many different hubs.\n  Model Generalizing convolution Graphs are non-Euclidean domains, meaning that they do not share the flat, grid-like structure of the Euclidean space, but instead have a non-trivial structure; this structure is informative, and should be accounted for along with the information coming from the data on the domain. Nevertheless, many of the operations employed by the building blocks of deep neural networks rely on this structure, convolution being one of them. The latter enforces by construction useful priors that we would like to inject in our learning models, like self-similarity and locality, that have their importance also in the graph setting. Nonetheless, convolution cannot naturally be applied to non-Euclidean domains, and so different approaches have been suggested over the last years. For this project, we have employed two architectures which exploit totally different theoretical frameworks:\n Graph Attention Networks, which fall under the category of spatial approaches;\n Graph Convolutional Networks, which instead leverage spectral theory.\n  Graph Convolutional Network Spectral approaches have this name since they define the convolution operation on graphs’ nodes in the spectral, or Fourier, domain as the multiplication of a node signal \\(\\mathbf{x} \\in \\mathbb{R}^n\\) with a filter \\(\\mathbf{g}_{\\theta} = diag(g_{\\theta}^{(1)}, \\dots, g_{\\theta}^{(n)})\\) in the Fourier domain.\n\\[\\mathbf{g}_{\\theta} \\star \\mathbf{x} = \\mathbf{U} \\mathbf{g}_{\\theta} \\mathbf{U}^{\\top} \\mathbf{x}\\]\nThis definition exploits several properties. The first is the convolution theorem. The convolution theorem is a defining property of convolution and states that the Fourier transform diagonalizes convolution. \\[\\mathcal{F}\\{ (\\mathbf{g} \\star \\mathbf{x}) \\} = \\underbrace{\\mathcal{F}\\{ \\mathbf{g} \\} \\mathcal{F}\\{ \\mathbf{x} \\} }_{\\text{simple product}}\\] This means that the convolution of two signals, that in our case would be a node signal \\(\\mathbf{x}\\) in \\(\\mathbb{R}^n\\) and a parametrized filter \\(g_\\theta,\\) is a simple product, in the Fourier domain. However, the Fourier transform of a signal requires an integral, so it is not clearly defined on non-Euclidean domains, and so far we have only shifted the problem from convolution to Fourier transform. On the other hand, there is an operator, the Laplacian, that is a differential operator in \\(\\mathbb{R}^n\\) but that can be easily generalized to non-Euclidean domains, and for instance here we see its graph counterpart \\[\\Delta \\mathbf{f} = \\underbrace{\\left( \\mathbf{I}_n - \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\right)}_{\\text{normalized graph Laplacian}} \\mathbf{f}.\\]\nWhat is the connection between the two? We can think of the Fourier transform of a function as expressing that function as a weighted average of functions, with some proper coefficients. Looking at the formula, the coefficients are the values taken by the original function, while the the functions are members of the so called Fourier basis, and in the case of \\(\\mathbb{R}^n\\) are called plane waves, since they are complex sinusoids. \\[\\begin{aligned} \\mathcal{F}\\{ f(x) \\} = \\hat{f}(x) = \\int f(x) \\overbrace{e^{-2\\pi i x \\xi }}^{\\text{plane waves are Fourier basis}} dx \\\\ \\Delta \\underbrace{\\left( e^{-2\\pi i x \\xi} \\right)}_{\\text{plane wave}} = 4 \\pi^2 |\\xi|^2 \\underbrace{e^{-2\\pi i x \\xi}}_{\\text{Laplacian eigenfunction}}\\end{aligned}\\] It turns out that these plane waves are eigenfunctions of the Laplacian. We can now exploit this property by defining the Fourier basis on graphs to be the eigenvectors of the graph Laplacian, so that performing a Fourier transform is as simple as multiplying by the transposed matrix of eigenvectors. \\[\\begin{aligned} \\Delta = \\mathbf{U} \\mathbf*{\\Lambda} \\mathbf{U}^{\\top} \\\\ \\mathbf{\\hat{x}} = \\mathbf{U}^{\\top} \\mathbf{x}, \\qquad \\mathbf{x} = \\mathbf{U} \\mathbf{\\hat{x}}\\end{aligned}\\] Now, the initial formula is explained as bringing the node signal \\(\\mathbf{x}\\) in the Fourier domain, performing convolution as a simple element-wise, product, and then go back to the spatial domain. \\[\\mathbf{g}_{\\theta} \\star \\mathbf{x} = \\underbrace{\\mathbf{U}}_{\\text{back to spatial domain}} \\overbrace{\\mathbf{g}_{\\theta}}^{\\text{conv. in Fourier domain}} \\underbrace{\\mathbf{U}^{\\top} \\mathbf{x}}_{\\text{to Fourier domain}}\\] with \\(\\mathbf{g}_{\\theta} = \\mathbf{g}_{\\theta}(\\mathbf*{\\Lambda}) =\\) learnable spectral kernel functions of the Laplacian eigenvalues.\nNow, this was the theoretical background to define spectral convolution. Then, different spectral approaches implement this operation in different ways. For instance, the operation that the GCN layer implements is a simplification. In particular, two main simplifications are made. The first is that computing \\(g_\\theta\\), as a function of the eigenvalues, requires an eigendecomposition which is computationally expensive. So, we can approximate it as a truncated expansion in terms of Chebyshev polynomials. These polynomials form an orthogonal basis for functions defined on the unit circle, so if we properly renormalize the matrix of eigenvalues we can approximate the filter up to some precision \\(K\\). This means that convolution now has the form\n\\[\\begin{aligned} \\mathbf{g}_{\\theta}(\\mathbf*{\\Lambda}) \\approx \\sum_{k=0}^K \\theta_k\u0026#39; T_k \\underbrace{(\\mathbf*{\\tilde{\\Lambda}})}_{\\text{renormalized}} \\\\ \\mathbf{g}_{\\theta}\u0026#39; \\star \\mathbf{x} \\approx \\sum_{k=0}^K \\theta_k\u0026#39; T_k (\\mathbf*{\\tilde{L}}) \\mathbf{x}\\end{aligned}\\]\nNotice how the Laplacian enters up to its \\(K\\)-th power, meaning that the output of the convolution for each node will depend on node signals from their \\(K\\)-th order neighborhood. The second simplification is that there is no reason to aggregate a \\(K\\)-order neighborhood, instead we could just stack \\(K\\) layers, each computing one hop. By restricting \\(K\\) to 1 we get \\[\\mathbf{g}_{\\theta}\u0026#39; \\star \\mathbf{x} \\approx \\theta_0\u0026#39; \\mathbf{x} - \\theta_1\u0026#39; \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{x}\\] The final simplification is just to reduce the number of free parameters, so we arrive to the actual implementation of the GCN layer. \\[\\mathbf{g}_{\\theta}\u0026#39; \\star \\mathbf{x} \\approx \\overbrace{\\theta}^{\\text{learnable}} \\underbrace{\\left( \\mathbf{I}_n + \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}} \\right)}_{\\text{fixed}} \\mathbf{x}\\] Notice that this whole expression is fixed, meaning it has no learnable parameters and is computed once as a preprocessing step.\nGraph Attention Network Now, GCN suffers from several problems. The first is something inherent to all spectral approaches, they cannot be transferred to unseen graphs. In particular, for GCN since the matrix \\(\\mathbf*{\\tilde{A}} = \\mathbf{I}_n + \\mathbf{D}^{-\\frac{1}{2}} \\mathbf{A} \\mathbf{D}^{-\\frac{1}{2}}\\) is computed with degree and adjacency matrix of the training graph, that will be different for unseen graphs. This is not limiting for us, since the social graph is indeed fixed, but can of course be very limiting.\nThe second is that the learnable parameters \\(\\mathbf{\\theta}\\) are shared across the nodes in a neighborhood. Here, the neighborhood of node 1, that has signal \\(x_1\\), is associated with \\(\\theta_1\\), meaning all the nodes in this neighborhood have importance \\(\\theta_1\\). As said before, GAT is a type of spatial approach, that addresses these problems by defining convolution directly in the spatial domain. In particular, a convolutional attention layer does the following computation. It receives in input a set of node features. \\[\\mathbf{H} = \\{\\ \\mathbf{h}_1, \\dots, \\mathbf{h}_n \\}, ~ \\mathbf{h}_i \\in \\mathbb{R}^F\\] Then applies a shared linear transformation to every node. \\[\\mathbf{h}_i \\mapsto \\mathbf{W} \\mathbf{h}_i = \\mathbf*{\\tilde{h}}_i\\] Now, let’s focus on a single node, the \\(i\\)-th node. We have to somehow aggregate the node signals from its neighbors. GAT does so by assigning attention coefficients to each neighbor \\(j\\). \\[\\alpha_{ij} = \\mathrm{softmax}_j (e_{ij}) ~~ e_{ij} = a(\\mathbf*{\\tilde{h}}_i, \\mathbf*{\\tilde{h}}_j) = \\sigma(\\mathbf{a}^{\\top} [\\mathbf*{\\tilde{h}}_i; \\mathbf*{\\tilde{h}}_j])\\] These coefficients determine how important the signal of node \\(j\\) is for node \\(i\\), and are computed with an attention mechanism called masked attention, implemented as a single layer MLP.\nFinally, we compute a linear combination of the features of the neighbors, weighted by these attention coefficients. \\[\\mathbf{h}\u0026#39;_i = \\sigma \\left( \\sum_{j \\in \\mathcal{N}_i} \\alpha_{ij} \\mathbf*{\\tilde{h}}_j \\right).\\]\nA self-loop is injected in the network since of course the feature of node \\(i\\) itself should be taken into consideration, and then a nonlinearity is applied to produce the new hidden feature for node \\(i\\).\n image  Results We evaluated our model with both the convolutional layers presented before, and also with both the real and synthetic data, to draft a comparison. The model performance is evaluated in terms of F1 score, since we trained it with binary cross entropy and hence it performs classification. Nevertheless, if we aggregate this prediction, i.e. we employ the graph sum pooling just at inference time, all the models showed better performance on the virality prediction as defined in principle, that is a regression on the whole social graph, with different node signals for different cascades.\n   Real Synthetic    GCN 0.727 0.744  GAT 0.784 0.829    Conclusions To recap, in this project we propose a Geometric Deep Learning approach to the problem of virality prediction on social networks, specifically Twitter. The main difficulty we faced during the project has been on data. In fact, data was difficult to obtain, we expected to find some datasets that suited our needs, but instead with the GDPR policies Twitter strictly limited the circulation of its data, and so we had to access it through its APIs and actually build our own dataset. This leads to the second problem. This data is sparse, in fact very sparse. We think that on social networks information has a natural tendency to spread widely, but this is a bias, since most of the examples we come up with pop to our mind exactly because they spread widely. We do not think of the majority of content, that simply gets uploaded and shared by little to nobody. So wide spread of information is rare, and this means that a learning model has to learn spreading patterns with very few informative samples.\nThis is a general, unsolved problem. We saw some recent related work, solving (so to speak) the problem by carefully selecting informative samples among a huge collection of scraped data. This induces a bias, since the data that the model is shown does not correspond to how data in the real world is distributed. So, a possibility for future work on the project, and in general on this field, might be on how to apply signal processing techniques for reconstructing sparse signals, like compressed sensing, on non-Euclidean domains, like graphs.\n","date":1596240000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596240000,"objectID":"d3c0b6d932173fbdb6156b061e2f478e","permalink":"//localhost:1313/project/vp/","publishdate":"2020-08-01T00:00:00Z","relpermalink":"/project/vp/","section":"project","summary":"Implementation of an ad-hoc graph neural network to predict how much a given Twitter hashtag will spread through the social network.","tags":["Geometric Deep Learning","Social Networks","Graph Machine Learning","Deep Learning"],"title":"Virality Prediction via Graph Neural Networks","type":"project"},{"authors":null,"categories":null,"content":"Introduction Motivation During the last few decades, we have witnessed the rise of web services offering any kind of goods, take for example Netflix for movies or Amazon for products. Such sites usually have huge catalogues of items that can overwhelm the user with too much information, making it hard for him to find items he would like; being able to narrow this large amount of contents is critical for these services, as it helps them generate greater incomes by suggesting users the right content to buy while also making them stand out from competitors as users find the service more useful.\nFormalization In a very general way, recommender systems are algorithms aimed at suggesting relevant items to users. Various approaches have been tried, among these we can define three families:\n content-based recommender systems, which create items and users profiles, embed them in a numerical feature space, and then suggest to the user the items which are nearest to him;\n collaborative-filtering recommender systems, which instead ignore content and rely only on user-item ratings; these furtherly divide in the way they suggest items to the user:\n user-based approaches suggest him items liked by users similar to him;\n item-based approaches instead suggest him items similar to items he liked;\n  and finally hybrid recommender systems, which leverage both approaches.\n  Sequential Recently, recommender systems have taken in consideration sequential dynamics, seeking to capture patterns in the sequence of actions users perform. Contrarily to temporal recommendation systems which explicitly take into account the time of the actions, sequential ones only consider the order of actions, modelling sequential patterns which are independent of time.\nAs any sequence pattern recognition task, the problem is challenging, since the number of possible sequences grow exponentially with the number of past actions used as context. Markov-Chain models overcome this issue by conditioning the next action only on the previous few actions, characterizing effectively short-range item transitions. To capture longer-range item dependencies, neural architectures have been used.\nData In this project we will see how recommender systems can be leveraged to suggest games; to do this, we will use a large dataset of Steam reviews, which is publicly available online.\nDescription The dataset contains information regarding both games and user-game reviews, separated in two tables steam_reviews and steam_games; here we can see the schemas\nsteam_reviews:\n username: reviewer username;\n user_id: reviewer id;\n product_id: reviewed game id;\n text: content of the review;\n date: date of the review;\n found_funny: number of users who found the review funny;\n hours: number of hours the user played the game;\n page: the page in which the review appears;\n page_order: ??\n products: ???\n compensation: ??\n  steam_games:\n title;\n id: game id;\n developer: company that developed the game;\n genres: genres of the game, e.g. action, adventure and so on;\n metascore: overall user score of the game;\n price: price of the game;\n discount_price: discounted price;\n publisher: company that published the game;\n release_date;\n reviews_url: url to the reviews of the game;\n specs: characteristics of the game;\n tags: tags of the game;\n url: link to the game;\n app_name: name of the application corresponding to the game;\n sentiment: overall sentiment of the game;\n early_access:\n  We will use two models, plus a naive baseline:\n MF model, which is a collaborative-filtering approach;\n RNN-based, which is a sequential recommendation approach;\n  Both don’t require item profiles, so we will not exploit the rich game features in steam_games, which may be used in a content-based or hybrid approach.\nAmong the listed features in the review table, only the first 5 are needed for our approach, so after a bit of preprocessing we obtain the following features\n user_id: reviewer id;\n product_id: reviewed game id;\n text: content of the review;\n date: date of the review;\n  so we have all we need to design the models.\nPlots The dataset exhibits some non-trivial properties, it is for example evident that the distribution of ratings follows a power-law both concerning users that games:\n Ratings per user.  as we can see in the figure most of the users reviewed few games, while only few users have reviewed a significant number of games. The same thing happens for games, few games received a large amount of reviews, while most games have few.\n Ratings per game.  The distribution shows a long tail which amounts for a significant part of the catalogue, so a good recommender system should be able to recommend less famous games, even if it is in fact harder.\n Long tail.  Preprocessing Two of the models we will see require an explicit ratings matrix in input; nevertheless, our dataset only provides us text reviews, which must be numerically handled somehow. There are approaches which work directly on implicit feedbacks, but considering reviews as binary features which model whether the user-item interaction is present or absent doesn’t make good use of the information, as a review is much richer and can be seen as a verbose rating.\nFor this task, we will use a pretrained sentiment analyzer from StanfordNLP, so every text review will be mapped to a value \\(r \\in \\{0, 1, 2\\}\\), encoding the sentiment as follows\n \\(0\\): negative;\n \\(1\\): neutral;\n \\(2\\): positive.\n  Allowing us to reduce the problem to the classical explicit feedback setting.\nAs we can see in the figure, reviews are fairly balanced, with most being neutral. Note that this may be true in the real distribution or a bias coming from the sentiment analyzer.\n Sentiment distribution.  Models Popularity based We will consider as a baseline a constant model, that is a model that suggests the same games to every user, independently from his tastes. As we don’t use any information regarding the user, the safest bet is to just suggest the most popular games.\nMatrix Factorization The first real model that we will try employs a Latent Factor CF approach. In general, latent factor models are statistical models that relate a set of observable variables (so-called manifest variables) to a set of latent variables. In our case we want to predict user ratings by representing both items and users with a number of hidden factors inferred from observed ratings.\nThe basic assumption is that there exist an unknown low-dimensional representation of users and items where user-item affinity can be modeled accurately. Matrix Factorization is a way to obtain these lower-dimensional representations directly from the observed data.\nIn general, we want to infer the rating \\(r_{u, i}\\) of user \\(u\\) to item \\(i\\);\nThe framework works as follow:\n map both items and users to a joint latent factor d-dimensional space, so\n each user will be represented by \\(\\mathbf{x}_u \\in \\mathbb{R}^d\\),\n each item will be represented by \\(\\mathbf{w}_i \\in \\mathbb{R}^d\\);\n  estimate \\(r_{u, i}\\) by applying the dot product \\[\\hat{r}_{u, i} = \\mathbf{x}^T_u \\cdot \\mathbf{w}_i = \\sum_{j=1}^{d} x_{u, j} w_{j, i}\\]\n recommend to user \\(u\\) the \\(k\\) items for which the estimate is maximum.\n  Easier said than done, as we need a reasonable way to map users and items to these latent factor vectors.\n Matrix Factorization.  What we can do is leverage the observed ratings which are contained in the matrix \\(R\\), and try to approximate \\(R\\) with the product of two matrices \\(X \\in \\mathbb{R}^{m \\times d}\\) and \\(W \\in \\mathbb{R}^{d \\times n}\\). This is equivalent to find the parameters that minimize the following loss function \\[\\mathcal{L}(X, W) = \\sum_{u, i \\in D} \\left( r_{u, i} - \\mathbf{x}^T_u \\cdot \\mathbf{w}_i \\right) ^2\\] plus possibly a regularization term.\nThe resulting optimization problem can be solved either with SGD or ALS; The former is an iterative method which tries to minimize the loss function by descending its gradient, going opposite to the direction of steepest increase; nevertheless, this approach doesn’t scale well when \\(R\\) grows large, therefore given the dimension of the ratings matrix in our scenario this may not be convenient.\nALS overcomes the non-convexity of the objective function by alternately fixing one latent vector and updating the other one; when one latent vector is fixed, the objective becomes quadratic and thus convex, allowing to find a closed-form solution.\nSequential Formalization To use sequential techniques we need to properly transform the dataset, obtaining for each user a vector \\[\\mathbf{x} = (x_1, \\dots, x_n)\\] where \\(x_i\\) is the embedding of the \\(i\\)-th game reviewed by the user, ordered by timestamp. We want the model to be able to predict the next game that will be reviewed by the user given the previous reviewed games, that is predicting \\(x_i\\) given \\(x_1, \\dots, x_{i-1}\\); To do this, we give the model the sequence of the first \\(n-1\\) reviews \\((x_1, \\dots, x_{n-1})\\) as input and train it to predict the input shifted by 1 position \\((x_2, \\dots, x_{n})\\). This is basically what in NLP is called language modeling, with the game ids composing the vocabulary.\n Input preprocessing.  Cross entropy is used as loss function, as each token prediction is a multilabel classification task \\[\\mathcal{L} = -\\sum_{c=1}^My_{o,c}\\log(p_{o,c})\\]\nLSTM As we have previously introduced, sequential recommender systems can exploit specialized neural architectures such as Recurrent Neural Networks; these summarize the context of a certain token \\(m\\) with a recurrently updated vector \\[\\vec{h}_m = g(\\vec{x}_m, \\vec{h}_{m-1}), \\quad m = 1,2, \\dots, m\\]\nwhere \\(\\vec{x}_m\\) is the vector embedding of the token \\(w_m\\) and \\(g\\) defines the recurrence. Nevertheless, RNNs often fail to capture long-time dependencies; for this reason, LSTMs are often used. These employ a more complex recurrence, in which a memory cell goes through a series of gates, in fact avoiding repeated applications of non-linearity. The hidden state \\(\\vec{h}_m\\) accounts for information in the input leading up to position \\(m\\), but it ignores the subsequent tokens, which may also be relevant to the tag \\(y_m\\); this can be addressed by adding a second LSTM, in which the input is reversed. This architecture is called Bidirectional LSTM, and is one of the most effective neural architectures for sequences; nevertheless, for how we modeled the problem it would allow the model to cheat, as for any intermediate prediction it would be able to peek at the next game in the sequence and give it in output correctly.\nSince the LSTM expects a batch of sequences of equal length, padding is added.\n Model architecture.  The model thus works as follows:\neach input sequence \\(\\mathbf{x}\\) is embedded by a word embedding layer;\n it is then passed to a LSTM encoder which takes as input the embedded sequence and returns a dynamic representation of each game and its context;\n the hidden representation is then given to a Multi Layer Perceptron that maps each game representation to the games space.\n  Results Metrics Root Mean Squared Error has been used as metric to evaluate the Matrix Factorization model, \\[{\\displaystyle \\text{RMSD} ={\\sqrt {\\frac {\\sum _{t=1}^{T}({\\hat {y}}_{t}-y_{t})^{2}}{T}}}.}\\]\nwhile Hit@\\(10\\) has been used for the sequential model, which is a top-\\(n\\) metric that counts the fraction of times that the ground-truth next item is among the top \\(10\\) recommended items.\n\\[\\frac{\\text{# hits}}{\\text{# users}}\\]\nResults Matrix Factorization In the table we can see the RMSE for the MF model against the popularity based baseline; while the results may not seem impressive, it must be noted that the problem is in fact challenging: sentiment analysis is still an open research field, the pretrained model that we have seen is said to reach an accuracy of \\(70\\%\\), the resulting error pile-up with the error produced by the recommender system may be severe; moreover, the game reviews may be particularly difficult for the analyzer to get right, as gamers are often ironic and have their own niche vocabulary of words and meanings.\nSequential In the table we can see the hit@10 score for the sequential model against the popularity baseline; an accuracy of \\(0.503\\) would be low in a typical classification setting with few classes, especially if we consider that the model has 10 tries; nevertheless, in this scenario the model must be able to discriminate among \\(8590\\) classes; to understand what that means, let’s see what score would achieve a random baseline. \\[\\begin{aligned} P\\left\\{hit\\right\\} \u0026amp;= \\sum_{i = 1}^{10} P\\left\\{pred_i \\text{ is correct} \\right\\}\\\\ \u0026amp;= \\sum_{i=1}^{10} \\frac{1}{\\text{# classes}} = 10 \\cdot \\frac{1}{8590} \\approx 1e^{-4}\\end{aligned}\\]\nStudy case As a study case, I tried to feed the model with my own rated games to see if the predictions fit my tastes; Let’s try to evaluate just the recommending part, so I am going to give the games directly numeric ratings so to skip the sentiment analyzer part.\nConclusions We have seen two very different approaches to recommender systems, neither of them reached state of the art: for example, attention-based sequential recommender systems have reached an hit ratio at \\(10\\) of \\(0.7\\) over the same dataset. The MF approach we have seen is too naive and doesn’t exploit all the available features which would make up for a good hybrid based recommender system, while the sequential approach using RNNs has few intrinsic flaws, for example the LSTM outputs a sequence of games where the same game is often repeated while it can’t happen in the gold truth, nevertheless it is not easy to carve such constraints in the model.\nIt would certainly be interesting to add content based features to both approaches, for example obtaining contextualized embeddings from the text reviews. For the sequential setting, it may be worth trying adding a sequence scorer on top of the LSTM, like a Conditional Random Field, to help assess the quality of a sequence of tags as a whole.\n","date":1604966400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1604966400,"objectID":"706739d7b5bf8151e9044cfdb8b3ba3c","permalink":"//localhost:1313/project/rs/","publishdate":"2020-11-10T00:00:00Z","relpermalink":"/project/rs/","section":"project","summary":"Comparison of classical recommender system approaches with sequential ones in a big data regime.","tags":["Deep Learning","Recommendation Systems","Matrix completion"],"title":"Different approaches for large-scale recommender systems","type":"project"},{"authors":[],"categories":null,"content":" Click on the Slides button above to view the built-in slides feature.   Slides can be added in a few ways:\n Create slides using Wowchemy\u0026rsquo;s Slides feature and link using slides parameter in the front matter of the talk file Upload an existing slide deck to static/ and link using url_slides parameter in the front matter of the talk file Embed your slides (e.g. Google Slides) or presentation video on this page using shortcodes.  Further event details, including page elements such as image galleries, can be added to the body of this page.\n","date":1906549200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1906549200,"objectID":"96344c08df50a1b693cc40432115cbe3","permalink":"//localhost:1313/talk/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/talk/example/","section":"talk","summary":"An example talk using Wowchemy's Markdown slides feature.","tags":[],"title":"Example Talk","type":"talk"},{"authors":[],"categories":[],"content":"Create slides in Markdown with Wowchemy Wowchemy | Documentation\n Features  Efficiently write slides in Markdown 3-in-1: Create, Present, and Publish your slides Supports speaker notes Mobile friendly slides   Controls  Next: Right Arrow or Space Previous: Left Arrow Start: Home Finish: End Overview: Esc Speaker notes: S Fullscreen: F Zoom: Alt + Click PDF Export: E   Code Highlighting Inline code: variable\nCode block:\nporridge = \u0026quot;blueberry\u0026quot; if porridge == \u0026quot;blueberry\u0026quot;: print(\u0026quot;Eating...\u0026quot;)   Math In-line math: $x + y = z$\nBlock math:\n$$ f\\left( x \\right) = ;\\frac{{2\\left( {x + 4} \\right)\\left( {x - 4} \\right)}}{{\\left( {x + 4} \\right)\\left( {x + 1} \\right)}} $$\n Fragments Make content appear incrementally\n{{% fragment %}} One {{% /fragment %}} {{% fragment %}} **Two** {{% /fragment %}} {{% fragment %}} Three {{% /fragment %}}  Press Space to play!\nOne  Two  Three \n A fragment can accept two optional parameters:\n class: use a custom style (requires definition in custom CSS) weight: sets the order in which a fragment appears   Speaker Notes Add speaker notes to your presentation\n{{% speaker_note %}} - Only the speaker can read these notes - Press `S` key to view {{% /speaker_note %}}  Press the S key to view the speaker notes!\n Only the speaker can read these notes Press S key to view    Themes  black: Black background, white text, blue links (default) white: White background, black text, blue links league: Gray background, white text, blue links beige: Beige background, dark text, brown links sky: Blue background, thin dark text, blue links    night: Black background, thick white text, orange links serif: Cappuccino background, gray text, brown links simple: White background, black text, blue links solarized: Cream-colored background, dark green text, blue links   Custom Slide Customize the slide style and background\n{{\u0026lt; slide background-image=\u0026quot;/media/boards.jpg\u0026quot; \u0026gt;}} {{\u0026lt; slide background-color=\u0026quot;#0000FF\u0026quot; \u0026gt;}} {{\u0026lt; slide class=\u0026quot;my-style\u0026quot; \u0026gt;}}   Custom CSS Example Let\u0026rsquo;s make headers navy colored.\nCreate assets/css/reveal_custom.css with:\n.reveal section h1, .reveal section h2, .reveal section h3 { color: navy; }   Questions? Ask\nDocumentation\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1549324800,"objectID":"0e6de1a61aa83269ff13324f3167c1a9","permalink":"//localhost:1313/slides/example/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/slides/example/","section":"slides","summary":"An introduction to using Wowchemy's Slides feature.","tags":[],"title":"Slides","type":"slides"},{"authors":["Donato Crisostomi","吳恩達"],"categories":["Demo","教程"],"content":"Overview  The Wowchemy website builder for Hugo, along with its starter templates, is designed for professional creators, educators, and teams/organizations - although it can be used to create any kind of site The template can be modified and customised to suit your needs. It\u0026rsquo;s a good platform for anyone looking to take control of their data and online identity whilst having the convenience to start off with a no-code solution (write in Markdown and customize with YAML parameters) and having flexibility to later add even deeper personalization with HTML and CSS You can work with all your favourite tools and apps with hundreds of plugins and integrations to speed up your workflows, interact with your readers, and much more   The template is mobile first with a responsive design to ensure that your site looks stunning on every device.  Get Started  👉 Create a new site 📚 Personalize your site 💬 Chat with the Wowchemy community or Hugo community 🐦 Twitter: @wowchemy @GeorgeCushen #MadeWithWowchemy 💡 Request a feature or report a bug for Wowchemy ⬆️ Updating Wowchemy? View the Update Guide and Release Notes  Crowd-funded open-source software To help us develop this template and software sustainably under the MIT license, we ask all individuals and businesses that use it to help support its ongoing maintenance and development via sponsorship.\n❤️ Click here to become a sponsor and help support Wowchemy\u0026rsquo;s future ❤️ As a token of appreciation for sponsoring, you can unlock these awesome rewards and extra features 🦄✨\nEcosystem  Wowchemy Admin: An admin tool to automatically import publications from BibTeX  Inspiration Check out the latest demo of what you\u0026rsquo;ll get in less than 10 minutes, or view the showcase of personal, project, and business sites.\nFeatures  Page builder - Create anything with widgets and elements Edit any type of content - Blog posts, publications, talks, slides, projects, and more! Create content in Markdown, Jupyter, or RStudio Plugin System - Fully customizable color and font themes Display Code and Math - Code highlighting and LaTeX math supported Integrations - Google Analytics, Disqus commenting, Maps, Contact Forms, and more! Beautiful Site - Simple and refreshing one page design Industry-Leading SEO - Help get your website found on search engines and social media Media Galleries - Display your images and videos with captions in a customizable gallery Mobile Friendly - Look amazing on every screen with a mobile friendly version of your site Multi-language - 34+ language packs including English, 中文, and Português Multi-user - Each author gets their own profile page Privacy Pack - Assists with GDPR Stand Out - Bring your site to life with animation, parallax backgrounds, and scroll effects One-Click Deployment - No servers. No databases. Only files.  Themes Wowchemy and its templates come with automatic day (light) and night (dark) mode built-in. Alternatively, visitors can choose their preferred mode - click the moon icon in the top right of the Demo to see it in action! Day/night mode can also be disabled by the site admin in params.toml.\nChoose a stunning theme and font for your site. Themes are fully customizable.\nLicense Copyright 2016-present George Cushen.\nReleased under the MIT license.\n","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1607817600,"objectID":"279b9966ca9cf3121ce924dca452bb1c","permalink":"//localhost:1313/post/getting-started/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/getting-started/","section":"post","summary":"Welcome 👋 We know that first impressions are important, so we've populated your new site with some initial content to help you get familiar with everything in no time.","tags":["Academic","开源"],"title":"Welcome to Wowchemy, the website builder for Hugo","type":"post"},{"authors":["Donato Crisostomi","Robert Ford"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.    Create your slides in Markdown - click the Slides button to check out the example.   Supplementary notes can be added here, including code, math, and images.\n","date":1372636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1372636800,"objectID":"ff6a19061a984819d30c916886db56ef","permalink":"//localhost:1313/publication/example/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/example/","section":"publication","summary":"Lorem ipsum dolor sit amet, consectetur adipiscing elit. Duis posuere tellus ac convallis placerat. Proin tincidunt magna sed ex sollicitudin condimentum.","tags":[],"title":"An example conference paper","type":"publication"}]